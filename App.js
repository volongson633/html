import React, { useState, useEffect, useRef, useCallback } from 'react';
import { Mic, Camera, Volume2, Hand, Users, ArrowRight } from 'lucide-react';

const AccessibilityBridge = () => {
  const [step, setStep] = useState('voice-detect');
  const [person1Type, setPerson1Type] = useState('');
  const [person2Type, setPerson2Type] = useState('');
  const [isListening, setIsListening] = useState(false);
  const [isCameraOn, setIsCameraOn] = useState(false);
  const [inputText, setInputText] = useState('');
  const [outputText, setOutputText] = useState('');
  const [conversionMode, setConversionMode] = useState('');
  const [isProcessing, setIsProcessing] = useState(false);
  const [voiceInput, setVoiceInput] = useState('');
  const [aiSpeaking, setAiSpeaking] = useState(false);
  const [detectedText, setDetectedText] = useState('');
  const [isDetecting, setIsDetecting] = useState(false);
  const videoRef = useRef(null);
  const canvasRef = useRef(null);
  const recognitionRef = useRef(null);
  const hasWelcomedRef = useRef(false);
  const handsRef = useRef(null);
  const cameraRef = useRef(null);

  const disabilityTypes = [
    { id: 'normal', label: 'Ng∆∞·ªùi b√¨nh th∆∞·ªùng', icon: Users, keywords: ['b√¨nh th∆∞·ªùng', 'kh√¥ng c√≥ v·∫•n ƒë·ªÅ', 'kh·ªèe'] },
    { id: 'blind', label: 'Ng∆∞·ªùi m√π', icon: Camera, keywords: ['m√π', 'kh√¥ng nh√¨n th·∫•y', 'khi·∫øm th·ªã'] },
    { id: 'mute', label: 'Ng∆∞·ªùi c√¢m', icon: Mic, keywords: ['c√¢m', 'kh√¥ng n√≥i ƒë∆∞·ª£c', 'khi·∫øm kh·∫©u'] },
    { id: 'deaf', label: 'Ng∆∞·ªùi ƒëi·∫øc', icon: Volume2, keywords: ['ƒëi·∫øc', 'kh√¥ng nghe ƒë∆∞·ª£c', 'khi·∫øm th√≠nh'] },
    { id: 'mute-deaf', label: 'Ng∆∞·ªùi c√¢m v√† ƒëi·∫øc', icon: Hand, keywords: ['c√¢m v√† ƒëi·∫øc', 'c√¢m ƒëi·∫øc'] }
  ];

  const communicationMatrix = {
    'normal-blind': ['text-audio', 'audio-audio'],
    'normal-mute': ['audio-text', 'audio-sign'],
    'normal-deaf': ['audio-text', 'audio-sign'],
    'blind-blind': ['audio-audio'],
    'mute-mute': ['text-text', 'sign-sign', 'audio-audio'],
    'mute-deaf': ['text-text', 'text-sign', 'sign-sign'],
    'deaf-deaf': ['text-text', 'text-sign', 'sign-text', 'sign-sign'],
    'deaf-blind': ['text-audio', 'sign-audio'],
    'mute-deaf-mute-deaf': ['text-text', 'text-sign', 'sign-text', 'sign-sign']
  };

  const getModeLabel = (mode) => {
    const labels = {
      'text-audio': 'VƒÉn b·∫£n ‚Üí √Çm thanh',
      'audio-text': '√Çm thanh ‚Üí VƒÉn b·∫£n',
      'text-text': 'VƒÉn b·∫£n ‚Üí VƒÉn b·∫£n',
      'audio-audio': '√Çm thanh ‚Üí √Çm thanh',
      'sign-audio': 'Ng√¥n ng·ªØ k√Ω hi·ªáu ‚Üí √Çm thanh',
      'audio-sign': '√Çm thanh ‚Üí Ng√¥n ng·ªØ k√Ω hi·ªáu',
      'text-sign': 'VƒÉn b·∫£n ‚Üí Ng√¥n ng·ªØ k√Ω hi·ªáu',
      'sign-text': 'Ng√¥n ng·ªØ k√Ω hi·ªáu ‚Üí VƒÉn b·∫£n',
      'sign-sign': 'Ng√¥n ng·ªØ k√Ω hi·ªáu ‚Üí Ng√¥n ng·ªØ k√Ω hi·ªáu'
    };
    return labels[mode] || mode;
  };

  const determineConversionModes = () => {
    if (!person1Type || !person2Type) return [];
    const key1 = `${person1Type}-${person2Type}`;
    const key2 = `${person2Type}-${person1Type}`;
    return communicationMatrix[key1] || communicationMatrix[key2] || [];
  };

  const speakText = useCallback((text) => {
    if (!text) return;
    
    // Ki·ªÉm tra xem SpeechSynthesis c√≥ s·∫µn kh√¥ng
    if (!('speechSynthesis' in window)) {
      console.warn('SpeechSynthesis kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£');
      return;
    }
    
    try {
      // D·ª´ng t·∫•t c·∫£ gi·ªçng n√≥i ƒëang ph√°t tr∆∞·ªõc ƒë√≥
      if (window.speechSynthesis.speaking) {
        window.speechSynthesis.cancel();
      }
      
      setAiSpeaking(true);
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.lang = 'vi-VN';
      utterance.rate = 1.0;
      utterance.pitch = 1.0;
      utterance.volume = 1.0;
      
      utterance.onend = () => {
        setAiSpeaking(false);
      };
      
      utterance.onerror = (event) => {
        console.error('Speech synthesis error:', event);
        setAiSpeaking(false);
      };
      
      // ƒê·ª£i m·ªôt ch√∫t ƒë·ªÉ ƒë·∫£m b·∫£o cancel ƒë√£ ho√†n t·∫•t (n·∫øu c√≥)
      if (window.speechSynthesis.speaking) {
        setTimeout(() => {
          window.speechSynthesis.speak(utterance);
        }, 100);
      } else {
        window.speechSynthesis.speak(utterance);
      }
    } catch (error) {
      console.error('L·ªói khi ph√°t gi·ªçng n√≥i:', error);
      setAiSpeaking(false);
    }
  }, []);

  const detectDisabilityFromVoice = (text) => {
    const lowerText = text.toLowerCase();
    for (const type of disabilityTypes) {
      for (const keyword of type.keywords) {
        if (lowerText.includes(keyword)) {
          return type.id;
        }
      }
    }
    return null;
  };

  const startVoiceDetection = useCallback(() => {
    // Ki·ªÉm tra n·∫øu ƒë√£ c√≥ recognition ƒëang ch·∫°y th√¨ d·ª´ng l·∫°i
    if (recognitionRef.current) {
      try {
        recognitionRef.current.stop();
      } catch (e) {
        // Ignore error
      }
      recognitionRef.current = null;
    }

    if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
      alert('Tr√¨nh duy·ªát kh√¥ng h·ªó tr·ª£ nh·∫≠n di·ªán gi·ªçng n√≥i. Vui l√≤ng s·ª≠ d·ª•ng Chrome ho·∫∑c Edge.');
      return;
    }

    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    recognitionRef.current = new SpeechRecognition();
    recognitionRef.current.lang = 'vi-VN';
    recognitionRef.current.continuous = true;
    recognitionRef.current.interimResults = true;
    recognitionRef.current.maxAlternatives = 1;

    recognitionRef.current.onresult = (event) => {
      let interimTranscript = '';
      let finalTranscript = '';
      
      for (let i = event.resultIndex; i < event.results.length; i++) {
        const transcript = event.results[i][0].transcript;
        if (event.results[i].isFinal) {
          finalTranscript += transcript;
        } else {
          interimTranscript += transcript;
        }
      }
      
      // Hi·ªÉn th·ªã text ngay l·∫≠p t·ª©c (c·∫£ interim v√† final)
      setVoiceInput(finalTranscript || interimTranscript);
      
      if (finalTranscript) {
        if (step === 'voice-detect' && !person1Type) {
          const detected = detectDisabilityFromVoice(finalTranscript);
          if (detected) {
            setPerson1Type(detected);
            try {
              recognitionRef.current.stop();
            } catch (e) {
              // Ignore error
            }
            setIsListening(false);
            speakText(`ƒê√£ nh·∫≠n di·ªán: ${disabilityTypes.find(t => t.id === detected)?.label}. B√¢y gi·ªù, ng∆∞·ªùi th·ª© hai vui l√≤ng n√≥i v·ªÅ t√¨nh tr·∫°ng c·ªßa m√¨nh.`);
            setTimeout(() => {
              setVoiceInput('');
              // Ch·ªù AI n√≥i xong (8 gi√¢y) m·ªõi b·∫Øt ƒë·∫ßu ghi √¢m l·∫°i
              setTimeout(() => {
                startVoiceDetection();
              }, 8000);
            }, 1000);
          }
        } else if (step === 'voice-detect' && person1Type && !person2Type) {
          const detected = detectDisabilityFromVoice(finalTranscript);
          if (detected) {
            setPerson2Type(detected);
            try {
              recognitionRef.current.stop();
            } catch (e) {
              // Ignore error
            }
            setIsListening(false);
            speakText(`ƒê√£ nh·∫≠n di·ªán: ${disabilityTypes.find(t => t.id === detected)?.label}. H·ªá th·ªëng ƒëang t·ª± ƒë·ªông k·∫øt n·ªëi cho hai b·∫°n.`);
            // T·ª± ƒë·ªông chuy·ªÉn sang b∆∞·ªõc communicate ngay l·∫≠p t·ª©c, kh√¥ng c·∫ßn ch·ªù
            setTimeout(() => {
              const modes = determineConversionModes();
              if (modes.length > 0) {
                setConversionMode(modes[0]);
                setStep('communicate');
                // useEffect s·∫Ω t·ª± ƒë·ªông b·∫Øt ƒë·∫ßu mic/camera n·∫øu c·∫ßn
                speakText(`ƒê√£ s·∫µn s√†ng. Ch·∫ø ƒë·ªô: ${getModeLabel(modes[0])}. H·ªá th·ªëng s·∫Ω t·ª± ƒë·ªông b·∫Øt ƒë·∫ßu c√°c t√≠nh nƒÉng c·∫ßn thi·∫øt.`);
              } else {
                speakText('Xin l·ªói, kh√¥ng t√¨m th·∫•y ph∆∞∆°ng th·ª©c giao ti·∫øp ph√π h·ª£p. Vui l√≤ng th·ª≠ l·∫°i.');
              }
            }, 2000);
          }
        }
      }
    };

    recognitionRef.current.onstart = () => {
      setIsListening(true);
    };

    recognitionRef.current.onerror = (event) => {
      console.error('Speech recognition error:', event.error);
      if (event.error === 'not-allowed') {
        alert('Vui l√≤ng cho ph√©p truy c·∫≠p micro ƒë·ªÉ s·ª≠ d·ª•ng t√≠nh nƒÉng n√†y.');
      }
      setIsListening(false);
    };

    recognitionRef.current.onend = () => {
      setIsListening(false);
      // Kh√¥ng t·ª± ƒë·ªông kh·ªüi ƒë·ªông l·∫°i n·ªØa
    };

    try {
      recognitionRef.current.start();
    } catch (e) {
      console.error('Failed to start recognition:', e);
      setIsListening(false);
    }
  }, [step, person1Type, person2Type, speakText]);

  useEffect(() => {
    if (step === 'voice-detect') {
      // D·ª´ng t·∫•t c·∫£ speech recognition ƒëang ch·∫°y
      if (recognitionRef.current) {
        try {
          recognitionRef.current.stop();
        } catch (e) {
          // Ignore error
        }
        recognitionRef.current = null;
      }
      
      let startRecognitionTimeout;
      
      // Ch·ªâ ph√°t l·ªùi ch√†o l·∫ßn ƒë·∫ßu ti√™n khi v√†o trang (ch∆∞a c√≥ person1Type)
      if (!hasWelcomedRef.current && !person1Type) {
        hasWelcomedRef.current = true;
        
        // Ch·ªù 1s r·ªìi m·ªõi n√≥i
        const welcomeTimeout = setTimeout(() => {
          speakText('Xin ch√†o! Ch√†o m·ª´ng b·∫°n ƒë·∫øn v·ªõi ·ª©ng d·ª•ng C·∫ßu N·ªëi Giao Ti·∫øp. B·∫°n c√≥ v·∫•n ƒë·ªÅ g√¨ v·ªÅ giao ti·∫øp? Vui l√≤ng n√≥i r√µ t√¨nh tr·∫°ng c·ªßa b·∫°n.');
          
          // Ch·ªù AI n√≥i xong (kho·∫£ng 10 gi√¢y) r·ªìi m·ªõi b·∫Øt ƒë·∫ßu ghi √¢m
          startRecognitionTimeout = setTimeout(() => {
            if (step === 'voice-detect') {
              startVoiceDetection();
            }
          }, 12000);
        }, 1000);
        
        return () => {
          clearTimeout(welcomeTimeout);
          if (startRecognitionTimeout) {
            clearTimeout(startRecognitionTimeout);
          }
          if (recognitionRef.current) {
            try {
              recognitionRef.current.stop();
            } catch (e) {
              // Ignore error
            }
          }
          window.speechSynthesis.cancel();
        };
      } else {
        // C√°c tr∆∞·ªùng h·ª£p kh√°c: ƒë√£ c√≥ person1Type ho·∫∑c ƒë√£ welcome r·ªìi
        // N·∫øu ch∆∞a c√≥ person2Type th√¨ b·∫Øt ƒë·∫ßu ghi √¢m ngay
        if (!person2Type) {
          startVoiceDetection();
        }
      }
    }
    
    return () => {
      if (recognitionRef.current) {
        try {
          recognitionRef.current.stop();
        } catch (e) {
          // Ignore error
        }
      }
      // Ch·ªâ cancel speech synthesis khi component unmount, kh√¥ng cancel khi dependencies thay ƒë·ªïi
      // window.speechSynthesis.cancel();
    };
  }, [step, person1Type, person2Type, speakText, startVoiceDetection]);

  // T·ª± ƒë·ªông b·∫Øt ƒë·∫ßu mic/camera khi chuy·ªÉn sang b∆∞·ªõc communicate
  useEffect(() => {
    if (step === 'communicate' && conversionMode) {
      const needsMic = conversionMode.startsWith('audio') || conversionMode === 'sign-audio';
      const needsCamera = conversionMode.startsWith('sign');
      
      // T·ª± ƒë·ªông b·∫Øt ƒë·∫ßu c√°c t√≠nh nƒÉng c·∫ßn thi·∫øt sau 1 gi√¢y
      const autoStartTimeout = setTimeout(() => {
        if (needsMic && !isListening) {
          // G·ªçi startListening tr·ª±c ti·∫øp
          if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
            console.warn('Tr√¨nh duy·ªát kh√¥ng h·ªó tr·ª£ nh·∫≠n di·ªán gi·ªçng n√≥i');
            return;
          }

          const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
          if (recognitionRef.current) {
            try {
              recognitionRef.current.stop();
            } catch (e) {
              // Ignore
            }
          }
          
          recognitionRef.current = new SpeechRecognition();
          recognitionRef.current.lang = 'vi-VN';
          recognitionRef.current.continuous = true;
          recognitionRef.current.interimResults = true;
          recognitionRef.current.maxAlternatives = 1;

          recognitionRef.current.onresult = (event) => {
            let interimTranscript = '';
            let finalTranscript = '';
            
            for (let i = event.resultIndex; i < event.results.length; i++) {
              const transcript = event.results[i][0].transcript;
              if (event.results[i].isFinal) {
                finalTranscript += transcript;
              } else {
                interimTranscript += transcript;
              }
            }
            
            setInputText(finalTranscript || interimTranscript);
          };

          recognitionRef.current.onstart = () => {
            setIsListening(true);
          };

          recognitionRef.current.onerror = (event) => {
            console.error('Speech recognition error:', event.error);
            setIsListening(false);
          };

          try {
            recognitionRef.current.start();
          } catch (e) {
            console.error('Failed to start recognition:', e);
            setIsListening(false);
          }
        }
        
        if (needsCamera && !isCameraOn) {
          // G·ªçi startCamera tr·ª±c ti·∫øp
          navigator.mediaDevices.getUserMedia({ 
            video: { 
              width: 640, 
              height: 480,
              facingMode: 'user'
            } 
          }).then(stream => {
            if (videoRef.current) {
              videoRef.current.srcObject = stream;
              
              videoRef.current.onloadedmetadata = () => {
                if (canvasRef.current) {
                  canvasRef.current.width = videoRef.current.videoWidth;
                  canvasRef.current.height = videoRef.current.videoHeight;
                }
                
                // Kh·ªüi t·∫°o MediaPipe Hands n·∫øu ch∆∞a c√≥
                if (!handsRef.current) {
                  const checkMediaPipe = setInterval(() => {
                    if (typeof window.Hands !== 'undefined' && typeof window.Camera !== 'undefined') {
                      clearInterval(checkMediaPipe);
                      
                      const hands = new window.Hands({
                        locateFile: (file) => {
                          return `https://cdn.jsdelivr.net/npm/@mediapipe/hands@0.4.1675469404/${file}`;
                        }
                      });

                      hands.setOptions({
                        maxNumHands: 1,
                        modelComplexity: 1,
                        minDetectionConfidence: 0.5,
                        minTrackingConfidence: 0.5
                      });

                      hands.onResults((results) => {
                        if (canvasRef.current && videoRef.current && results.image) {
                          const canvasCtx = canvasRef.current.getContext('2d');
                          canvasCtx.save();
                          canvasCtx.clearRect(0, 0, canvasRef.current.width, canvasRef.current.height);
                          canvasCtx.drawImage(results.image, 0, 0, canvasRef.current.width, canvasRef.current.height);

                          if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
                            if (window.drawConnectors && window.drawLandmarks && window.HAND_CONNECTIONS) {
                              for (const landmarks of results.multiHandLandmarks) {
                                window.drawConnectors(canvasCtx, landmarks, window.HAND_CONNECTIONS,
                                                     {color: '#00FF00', lineWidth: 2});
                                window.drawLandmarks(canvasCtx, landmarks, {color: '#FF0000', lineWidth: 1, radius: 3});
                              }
                            }

                            // Nh·∫≠n di·ªán c·ª≠ ch·ªâ
                            const landmarks = results.multiHandLandmarks[0];
                            // S·ª≠ d·ª•ng gestureDictionary tr·ª±c ti·∫øp
                            let detectedGesture = null;
                            for (const [gesture, checkFunction] of Object.entries(gestureDictionary)) {
                              if (checkFunction(landmarks)) {
                                detectedGesture = gesture;
                                break;
                              }
                            }
                            
                            if (detectedGesture) {
                              setDetectedText(prev => {
                                if (prev.slice(-1) !== detectedGesture) {
                                  const newText = prev + detectedGesture;
                                  setInputText(newText);
                                  return newText;
                                }
                                return prev;
                              });
                            }
                          }
                          canvasCtx.restore();
                        }
                      });

                      handsRef.current = hands;
                      
                      // B·∫Øt ƒë·∫ßu nh·∫≠n di·ªán
                      setIsDetecting(true);
                      let isProcessing = true;
                      const processFrame = async () => {
                        if (videoRef.current && videoRef.current.readyState === videoRef.current.HAVE_ENOUGH_DATA && handsRef.current && isProcessing) {
                          try {
                            await handsRef.current.send({ image: videoRef.current });
                          } catch (error) {
                            console.error('Error processing frame:', error);
                          }
                        }
                        if (isProcessing && videoRef.current && videoRef.current.srcObject) {
                          requestAnimationFrame(processFrame);
                        }
                      };
                      processFrame();
                      
                      videoRef.current._stopProcessing = () => {
                        isProcessing = false;
                      };
                    }
                  }, 100);

                  setTimeout(() => {
                    clearInterval(checkMediaPipe);
                  }, 10000);
                } else {
                  // N·∫øu ƒë√£ c√≥ hands, b·∫Øt ƒë·∫ßu nh·∫≠n di·ªán ngay
                  setIsDetecting(true);
                  let isProcessing = true;
                  const processFrame = async () => {
                    if (videoRef.current && videoRef.current.readyState === videoRef.current.HAVE_ENOUGH_DATA && handsRef.current && isProcessing) {
                      try {
                        await handsRef.current.send({ image: videoRef.current });
                      } catch (error) {
                        console.error('Error processing frame:', error);
                      }
                    }
                    if (isProcessing && videoRef.current && videoRef.current.srcObject) {
                      requestAnimationFrame(processFrame);
                    }
                  };
                  processFrame();
                  
                  videoRef.current._stopProcessing = () => {
                    isProcessing = false;
                  };
                }
              };
            }
            setIsCameraOn(true);
          }).catch(err => {
            console.error('Kh√¥ng th·ªÉ truy c·∫≠p camera:', err);
          });
        }
      }, 1000);

      return () => clearTimeout(autoStartTimeout);
    }
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, [step, conversionMode, isListening, isCameraOn]);

  // T·ª´ ƒëi·ªÉn c·ª≠ ch·ªâ tay c∆° b·∫£n (c√≥ th·ªÉ m·ªü r·ªông)
  const gestureDictionary = {
    // Ch·ªØ c√°i c∆° b·∫£n
    'A': (landmarks) => {
      // Ng√≥n tay c√°i v√† 4 ng√≥n kh√°c n·∫Øm l·∫°i
      const thumbUp = landmarks[4].y < landmarks[3].y;
      const fingersDown = [landmarks[8].y > landmarks[6].y, landmarks[12].y > landmarks[10].y, 
                          landmarks[16].y > landmarks[14].y, landmarks[20].y > landmarks[18].y];
      return thumbUp && fingersDown.every(down => down);
    },
    'B': (landmarks) => {
      // T·∫•t c·∫£ ng√≥n tay du·ªói th·∫≥ng
      const fingersUp = [landmarks[4].y < landmarks[3].y, landmarks[8].y < landmarks[6].y,
                        landmarks[12].y < landmarks[10].y, landmarks[16].y < landmarks[14].y,
                        landmarks[20].y < landmarks[18].y];
      return fingersUp.every(up => up);
    },
    'C': (landmarks) => {
      // Ng√≥n tay cong nh∆∞ ch·ªØ C
      const thumbIn = landmarks[4].x > landmarks[3].x;
      const indexCurved = landmarks[8].y > landmarks[6].y && landmarks[8].x < landmarks[5].x;
      return thumbIn && indexCurved;
    },
    // S·ªë ƒë·∫øm
    '1': (landmarks) => {
      // Ch·ªâ ng√≥n tr·ªè du·ªói
      return landmarks[8].y < landmarks[6].y && 
             landmarks[12].y > landmarks[10].y && 
             landmarks[16].y > landmarks[14].y && 
             landmarks[20].y > landmarks[18].y;
    },
    '2': (landmarks) => {
      // Ng√≥n tr·ªè v√† ng√≥n gi·ªØa du·ªói
      return landmarks[8].y < landmarks[6].y && 
             landmarks[12].y < landmarks[10].y && 
             landmarks[16].y > landmarks[14].y && 
             landmarks[20].y > landmarks[18].y;
    },
    '3': (landmarks) => {
      // Ba ng√≥n ƒë·∫ßu du·ªói
      return landmarks[8].y < landmarks[6].y && 
             landmarks[12].y < landmarks[10].y && 
             landmarks[16].y < landmarks[14].y && 
             landmarks[20].y > landmarks[18].y;
    },
    '4': (landmarks) => {
      // B·ªën ng√≥n du·ªói (tr·ª´ ng√≥n c√°i)
      return landmarks[8].y < landmarks[6].y && 
             landmarks[12].y < landmarks[10].y && 
             landmarks[16].y < landmarks[14].y && 
             landmarks[20].y < landmarks[18].y;
    },
    '5': (landmarks) => {
      // T·∫•t c·∫£ ng√≥n tay du·ªói
      return landmarks[4].y < landmarks[3].y && 
             landmarks[8].y < landmarks[6].y && 
             landmarks[12].y < landmarks[10].y && 
             landmarks[16].y < landmarks[14].y && 
             landmarks[20].y < landmarks[18].y;
    },
    // C·ª≠ ch·ªâ ƒë∆°n gi·∫£n
    'OK': (landmarks) => {
      // Ng√≥n c√°i v√† ng√≥n tr·ªè t·∫°o v√≤ng tr√≤n
      const thumbIndexDistance = Math.sqrt(
        Math.pow(landmarks[4].x - landmarks[8].x, 2) + 
        Math.pow(landmarks[4].y - landmarks[8].y, 2)
      );
      return thumbIndexDistance < 0.05;
    },
    'THUMBS_UP': (landmarks) => {
      // Ng√≥n c√°i gi∆° l√™n
      return landmarks[4].y < landmarks[3].y && 
             landmarks[8].y > landmarks[6].y && 
             landmarks[12].y > landmarks[10].y && 
             landmarks[16].y > landmarks[14].y && 
             landmarks[20].y > landmarks[18].y;
    }
  };

  // Nh·∫≠n di·ªán c·ª≠ ch·ªâ t·ª´ landmarks
  const detectGesture = (landmarks) => {
    for (const [gesture, checkFunction] of Object.entries(gestureDictionary)) {
      if (checkFunction(landmarks)) {
        return gesture;
      }
    }
    return null;
  };

  // Kh·ªüi t·∫°o MediaPipe Hands
  const initializeHands = useCallback(() => {
    // ƒê·ª£i MediaPipe load
    const checkMediaPipe = setInterval(() => {
      if (typeof window.Hands !== 'undefined' && typeof window.Camera !== 'undefined') {
        clearInterval(checkMediaPipe);
        
        const hands = new window.Hands({
          locateFile: (file) => {
            return `https://cdn.jsdelivr.net/npm/@mediapipe/hands@0.4.1675469404/${file}`;
          }
        });

        hands.setOptions({
          maxNumHands: 1,
          modelComplexity: 1,
          minDetectionConfidence: 0.5,
          minTrackingConfidence: 0.5
        });

        hands.onResults((results) => {
          if (canvasRef.current && videoRef.current && results.image) {
            const canvasCtx = canvasRef.current.getContext('2d');
            canvasCtx.save();
            canvasCtx.clearRect(0, 0, canvasRef.current.width, canvasRef.current.height);
            canvasCtx.drawImage(results.image, 0, 0, canvasRef.current.width, canvasRef.current.height);

            if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
              // V·∫Ω landmarks n·∫øu c√≥ drawing utils
              if (window.drawConnectors && window.drawLandmarks && window.HAND_CONNECTIONS) {
                for (const landmarks of results.multiHandLandmarks) {
                  window.drawConnectors(canvasCtx, landmarks, window.HAND_CONNECTIONS,
                                       {color: '#00FF00', lineWidth: 2});
                  window.drawLandmarks(canvasCtx, landmarks, {color: '#FF0000', lineWidth: 1, radius: 3});
                }
              }

              // Nh·∫≠n di·ªán c·ª≠ ch·ªâ t·ª´ b√†n tay ƒë·∫ßu ti√™n
              const landmarks = results.multiHandLandmarks[0];
              const gesture = detectGesture(landmarks);
              
              if (gesture) {
                setDetectedText(prev => {
                  // Th√™m k√Ω t·ª± m·ªõi n·∫øu kh√°c v·ªõi k√Ω t·ª± cu·ªëi (tr√°nh l·∫∑p l·∫°i)
                  if (prev.slice(-1) !== gesture) {
                    const newText = prev + gesture;
                    // T·ª± ƒë·ªông c·∫≠p nh·∫≠t inputText
                    setInputText(newText);
                    return newText;
                  }
                  return prev;
                });
              }
            }
            canvasCtx.restore();
          }
        });

        handsRef.current = hands;
      }
    }, 100);

    // Timeout sau 10 gi√¢y
    setTimeout(() => {
      clearInterval(checkMediaPipe);
      if (!handsRef.current) {
        console.error('MediaPipe Hands kh√¥ng th·ªÉ t·∫£i');
        alert('Kh√¥ng th·ªÉ t·∫£i MediaPipe Hands. Vui l√≤ng ki·ªÉm tra k·∫øt n·ªëi internet.');
      }
    }, 10000);
  }, []);

  const startCamera = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ 
        video: { 
          width: 640, 
          height: 480,
          facingMode: 'user'
        } 
      });
      
      if (videoRef.current) {
        videoRef.current.srcObject = stream;
        
        // ƒê·ª£i video s·∫µn s√†ng
        videoRef.current.onloadedmetadata = () => {
          if (canvasRef.current) {
            canvasRef.current.width = videoRef.current.videoWidth;
            canvasRef.current.height = videoRef.current.videoHeight;
          }
          
          // Kh·ªüi t·∫°o MediaPipe Hands
          if (!handsRef.current) {
            initializeHands();
          }
          
          // B·∫Øt ƒë·∫ßu nh·∫≠n di·ªán sau khi MediaPipe ƒë√£ s·∫µn s√†ng
          const startDetection = () => {
            if (handsRef.current) {
              setIsDetecting(true);
              // S·ª≠ d·ª•ng requestAnimationFrame ƒë·ªÉ x·ª≠ l√Ω video
              let isProcessing = true;
              const processFrame = async () => {
                if (videoRef.current && videoRef.current.readyState === videoRef.current.HAVE_ENOUGH_DATA && handsRef.current && isProcessing) {
                  try {
                    await handsRef.current.send({ image: videoRef.current });
                  } catch (error) {
                    console.error('Error processing frame:', error);
                  }
                }
                if (isProcessing && videoRef.current && videoRef.current.srcObject) {
                  requestAnimationFrame(processFrame);
                }
              };
              processFrame();
              
              // L∆∞u h√†m d·ª´ng
              videoRef.current._stopProcessing = () => {
                isProcessing = false;
              };
            } else {
              // ƒê·ª£i MediaPipe s·∫µn s√†ng
              setTimeout(startDetection, 100);
            }
          };
          startDetection();
        };
      }
      setIsCameraOn(true);
    } catch (err) {
      alert('Kh√¥ng th·ªÉ truy c·∫≠p camera. Vui l√≤ng cho ph√©p quy·ªÅn truy c·∫≠p.');
    }
  };

  const stopCamera = () => {
    if (videoRef.current) {
      if (videoRef.current._stopProcessing) {
        videoRef.current._stopProcessing();
      }
      if (videoRef.current.srcObject) {
        videoRef.current.srcObject.getTracks().forEach(track => track.stop());
        videoRef.current.srcObject = null;
      }
    }
    if (cameraRef.current) {
      cameraRef.current.stop();
      cameraRef.current = null;
    }
    setIsCameraOn(false);
    setIsDetecting(false);
    setDetectedText('');
  };

  const startListening = () => {
    if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
      alert('Tr√¨nh duy·ªát kh√¥ng h·ªó tr·ª£ nh·∫≠n di·ªán gi·ªçng n√≥i');
      return;
    }

    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    recognitionRef.current = new SpeechRecognition();
    recognitionRef.current.lang = 'vi-VN';
    recognitionRef.current.continuous = true;
    recognitionRef.current.interimResults = true;
    recognitionRef.current.maxAlternatives = 1;

    recognitionRef.current.onresult = (event) => {
      let interimTranscript = '';
      let finalTranscript = '';
      
      for (let i = event.resultIndex; i < event.results.length; i++) {
        const transcript = event.results[i][0].transcript;
        if (event.results[i].isFinal) {
          finalTranscript += transcript;
        } else {
          interimTranscript += transcript;
        }
      }
      
      // Hi·ªÉn th·ªã ngay l·∫≠p t·ª©c
      setInputText(finalTranscript || interimTranscript);
    };

    recognitionRef.current.onstart = () => {
      setIsListening(true);
    };

    recognitionRef.current.onerror = (event) => {
      console.error('Speech recognition error:', event.error);
      setIsListening(false);
    };

    recognitionRef.current.start();
  };

  const stopListening = () => {
    if (recognitionRef.current) {
      recognitionRef.current.stop();
      setIsListening(false);
    }
  };

  const processConversion = async () => {
    if (!inputText.trim() && !isCameraOn) {
      alert('Vui l√≤ng nh·∫≠p n·ªôi dung ho·∫∑c b·∫≠t camera');
      return;
    }

    setIsProcessing(true);
    await new Promise(resolve => setTimeout(resolve, 1000));

    let result = '';
    if (conversionMode.includes('audio')) {
      if (conversionMode.startsWith('text') || conversionMode.startsWith('sign')) {
        speakText(inputText || 'Xin ch√†o, t√¥i ƒëang s·ª≠ d·ª•ng ng√¥n ng·ªØ k√Ω hi·ªáu');
        result = `üîä ƒêang ph√°t √¢m thanh: "${inputText || 'T·ª´ ng√¥n ng·ªØ k√Ω hi·ªáu'}"`;
      } else {
        result = inputText;
      }
    } else if (conversionMode.includes('sign')) {
      result = `üëã Chuy·ªÉn ƒë·ªïi sang ng√¥n ng·ªØ k√Ω hi·ªáu: ${inputText}`;
    } else {
      result = inputText;
    }

    setOutputText(result);
    setIsProcessing(false);
  };

  useEffect(() => {
    return () => {
      stopCamera();
      if (recognitionRef.current) {
        recognitionRef.current.stop();
      }
      window.speechSynthesis.cancel();
    };
  }, []);

  if (step === 'voice-detect') {
    return (
      <div className="min-h-screen p-8 bg-cover bg-center bg-no-repeat" style={{backgroundImage: 'url(https://img.freepik.com/vector-mien-phi/hinh-anh-minh-hoa-nhung-nguoi-khuyet-tat-ve-tay_23-2149651422.jpg?t=st=1768818612~exp=1768822212~hmac=97295c8c881599bf14063081a9aecd4c14612a3d4dbd24df6349a828735c2f36&w=1060)'}}>
        <div className="max-w-4xl mx-auto">
          <div className="text-center mb-12">
            <div className="inline-flex items-center justify-center w-20 h-20 bg-indigo-600 rounded-full mb-4 animate-pulse">
              <Mic className="w-10 h-10 text-white" />
            </div>
            <h1 className="text-4xl font-bold text-gray-900 mb-4">C·∫ßu N·ªëi Giao Ti·∫øp</h1>
            <p className="text-xl text-gray-600">ƒêang l·∫Øng nghe...</p>
          </div>

          <div className="bg-white rounded-2xl shadow-xl p-8 mb-8">
            <div className="flex items-center justify-center mb-6">
              <div className={`w-16 h-16 rounded-full ${isListening ? 'bg-red-500 animate-pulse' : 'bg-gray-300'} flex items-center justify-center`}>
                <Mic className="w-8 h-8 text-white" />
              </div>
            </div>

            <div className="space-y-4">
              <div className="bg-blue-50 p-4 rounded-lg">
                <p className="text-sm text-gray-600 mb-1">
                  {aiSpeaking ? 'üîä AI ƒëang n√≥i...' : isListening ? 'üëÇ ƒêang nghe, vui l√≤ng ch·ªù...' : '‚è∏Ô∏è ƒê√£ d·ª´ng'}
                </p>
                <p className="font-semibold text-blue-900">
                  {person1Type ? 'Ng∆∞·ªùi th·ª© hai, vui l√≤ng n√≥i v·ªÅ t√¨nh tr·∫°ng c·ªßa b·∫°n' : 'B·∫°n c√≥ v·∫•n ƒë·ªÅ g√¨ v·ªÅ giao ti·∫øp?'}
                </p>
              </div>

              {isListening && !voiceInput && !aiSpeaking && (
                <div className="bg-yellow-50 p-4 rounded-lg border-2 border-yellow-200 animate-pulse">
                  <p className="text-yellow-800 font-medium text-center">
                    üé§ ƒêang l·∫Øng nghe... H√£y n√≥i r√µ r√†ng
                  </p>
                </div>
              )}

              {voiceInput && (
                <div className="bg-gray-50 p-4 rounded-lg border-2 border-blue-300">
                  <p className="text-sm text-gray-600 mb-1">
                    {isListening ? 'üî¥ ƒêang ghi √¢m:' : '‚úì B·∫°n v·ª´a n√≥i:'}
                  </p>
                  <p className="text-gray-900 font-medium">{voiceInput}</p>
                </div>
              )}

              {person1Type && (
                <div className="bg-green-50 p-4 rounded-lg">
                  <p className="text-sm text-gray-600 mb-1">‚úì Ng∆∞·ªùi th·ª© nh·∫•t:</p>
                  <p className="font-semibold text-green-900">
                    {disabilityTypes.find(t => t.id === person1Type)?.label}
                  </p>
                </div>
              )}

              {person2Type && (
                <div className="bg-green-50 p-4 rounded-lg">
                  <p className="text-sm text-gray-600 mb-1">‚úì Ng∆∞·ªùi th·ª© hai:</p>
                  <p className="font-semibold text-green-900">
                    {disabilityTypes.find(t => t.id === person2Type)?.label}
                  </p>
                </div>
              )}
            </div>

            <div className="mt-6 p-4 bg-yellow-50 rounded-lg">
              <p className="text-sm text-yellow-800">
                üí° H∆∞·ªõng d·∫´n: H√£y n√≥i r√µ v·ªÅ t√¨nh tr·∫°ng c·ªßa b·∫°n, v√≠ d·ª•: "T√¥i b·ªã m√π", "T√¥i l√† ng∆∞·ªùi c√¢m", "T√¥i b·ªã ƒëi·∫øc"...
              </p>
            </div>

            <button
              onClick={() => {
                if (recognitionRef.current) {
                  recognitionRef.current.stop();
                }
                window.speechSynthesis.cancel();
                setStep('manual-select');
              }}
              className="w-full mt-6 bg-gray-200 hover:bg-gray-300 text-gray-700 font-semibold py-3 px-6 rounded-xl transition duration-200"
            >
              Ho·∫∑c ch·ªçn th·ªß c√¥ng
            </button>
          </div>
        </div>
      </div>
    );
  }

  if (step === 'manual-select') {
    return (
      <div className="min-h-screen p-8 bg-cover bg-center bg-no-repeat" style={{backgroundImage: 'url(https://images.unsplash.com/photo-1557683316-973673baf926?w=1920&q=80)'}}>
        <div className="max-w-6xl mx-auto">
          <div className="text-center mb-8">
            <h1 className="text-3xl font-bold text-gray-900 mb-2">Ch·ªçn lo·∫°i giao ti·∫øp</h1>
            <p className="text-gray-600">Vui l√≤ng ch·ªçn ƒë·∫∑c ƒëi·ªÉm c·ªßa hai ng∆∞·ªùi giao ti·∫øp</p>
          </div>

          <div className="grid grid-cols-1 md:grid-cols-2 gap-8 mb-8">
            <div className="bg-white rounded-2xl shadow-xl p-6">
              <h2 className="text-xl font-semibold mb-4 text-indigo-600">Ng∆∞·ªùi th·ª© nh·∫•t</h2>
              <div className="grid grid-cols-1 gap-3">
                {disabilityTypes.map((type) => {
                  const Icon = type.icon;
                  return (
                    <button
                      key={type.id}
                      onClick={() => setPerson1Type(type.id)}
                      className={`p-4 rounded-lg border-2 transition duration-200 flex items-center gap-3 ${
                        person1Type === type.id
                          ? 'border-indigo-600 bg-indigo-50'
                          : 'border-gray-200 hover:border-indigo-300'
                      }`}
                    >
                      <Icon className={`w-6 h-6 ${person1Type === type.id ? 'text-indigo-600' : 'text-gray-400'}`} />
                      <span className={`font-medium ${person1Type === type.id ? 'text-indigo-900' : 'text-gray-700'}`}>
                        {type.label}
                      </span>
                    </button>
                  );
                })}
              </div>
            </div>

            <div className="bg-white rounded-2xl shadow-xl p-6">
              <h2 className="text-xl font-semibold mb-4 text-green-600">Ng∆∞·ªùi th·ª© hai</h2>
              <div className="grid grid-cols-1 gap-3">
                {disabilityTypes.map((type) => {
                  const Icon = type.icon;
                  return (
                    <button
                      key={type.id}
                      onClick={() => setPerson2Type(type.id)}
                      className={`p-4 rounded-lg border-2 transition duration-200 flex items-center gap-3 ${
                        person2Type === type.id
                          ? 'border-green-600 bg-green-50'
                          : 'border-gray-200 hover:border-green-300'
                      }`}
                    >
                      <Icon className={`w-6 h-6 ${person2Type === type.id ? 'text-green-600' : 'text-gray-400'}`} />
                      <span className={`font-medium ${person2Type === type.id ? 'text-green-900' : 'text-gray-700'}`}>
                        {type.label}
                      </span>
                    </button>
                  );
                })}
              </div>
            </div>
          </div>

          <div className="flex gap-4">
            <button
              onClick={() => setStep('voice-detect')}
              className="flex-1 bg-gray-200 hover:bg-gray-300 text-gray-700 font-semibold py-4 px-6 rounded-xl transition duration-200"
            >
              Quay l·∫°i
            </button>
            <button
              onClick={() => {
                if (!person1Type || !person2Type) {
                  alert('Vui l√≤ng ch·ªçn c·∫£ hai lo·∫°i giao ti·∫øp');
                  return;
                }
                const modes = determineConversionModes();
                if (modes.length > 0) {
                  setConversionMode(modes[0]);
                  setStep('communicate');
                } else {
                  alert('Kh√¥ng t√¨m th·∫•y ph∆∞∆°ng th·ª©c giao ti·∫øp ph√π h·ª£p');
                }
              }}
              disabled={!person1Type || !person2Type}
              className={`flex-1 font-semibold py-4 px-6 rounded-xl transition duration-200 ${
                person1Type && person2Type
                  ? 'bg-indigo-600 hover:bg-indigo-700 text-white'
                  : 'bg-gray-300 text-gray-500 cursor-not-allowed'
              }`}
            >
              Ti·∫øp t·ª•c
            </button>
          </div>
        </div>
      </div>
    );
  }

  if (step === 'communicate') {
    const modes = determineConversionModes();
    const needsMic = conversionMode.startsWith('audio') || conversionMode === 'sign-audio';
    const needsCamera = conversionMode.startsWith('sign');

    return (
      <div className="min-h-screen p-8 bg-cover bg-center bg-no-repeat" style={{backgroundImage: 'url(https://images.unsplash.com/photo-1557683316-973673baf926?w=1920&q=80)'}}>
        <div className="max-w-6xl mx-auto">
          <div className="bg-white rounded-2xl shadow-xl p-6 mb-6">
            <div className="flex items-center justify-between mb-4">
              <h1 className="text-2xl font-bold text-gray-900">Giao ti·∫øp</h1>
              <button
                onClick={() => {
                  stopCamera();
                  stopListening();
                  setStep('voice-detect');
                  setPerson1Type('');
                  setPerson2Type('');
                  hasWelcomedRef.current = false;
                }}
                className="px-4 py-2 bg-gray-200 hover:bg-gray-300 rounded-lg transition duration-200"
              >
                B·∫Øt ƒë·∫ßu l·∫°i
              </button>
            </div>
            
            <div className="flex items-center gap-4 mb-4">
              <div className="flex-1 bg-indigo-50 p-3 rounded-lg">
                <p className="text-sm text-gray-600">Ng∆∞·ªùi 1</p>
                <p className="font-semibold text-indigo-900">
                  {disabilityTypes.find(t => t.id === person1Type)?.label}
                </p>
              </div>
              <ArrowRight className="w-6 h-6 text-gray-400" />
              <div className="flex-1 bg-green-50 p-3 rounded-lg">
                <p className="text-sm text-gray-600">Ng∆∞·ªùi 2</p>
                <p className="font-semibold text-green-900">
                  {disabilityTypes.find(t => t.id === person2Type)?.label}
                </p>
              </div>
            </div>

            {modes.length > 1 && (
              <div className="mb-4">
                <label className="block text-sm font-medium text-gray-700 mb-2">
                  Ch·ªçn ph∆∞∆°ng th·ª©c chuy·ªÉn ƒë·ªïi:
                </label>
                <select
                  value={conversionMode}
                  onChange={(e) => setConversionMode(e.target.value)}
                  className="w-full p-3 border border-gray-300 rounded-lg focus:ring-2 focus:ring-indigo-500 focus:border-transparent"
                >
                  {modes.map(mode => (
                    <option key={mode} value={mode}>{getModeLabel(mode)}</option>
                  ))}
                </select>
              </div>
            )}

            <div className="bg-blue-50 p-4 rounded-lg">
              <p className="text-sm text-gray-600 mb-1">Ch·∫ø ƒë·ªô hi·ªán t·∫°i:</p>
              <p className="text-lg font-semibold text-blue-900">{getModeLabel(conversionMode)}</p>
            </div>
          </div>

          <div className="grid grid-cols-1 md:grid-cols-2 gap-6">
            <div className="bg-white rounded-2xl shadow-xl p-6">
              <h2 className="text-xl font-semibold mb-4 text-gray-900">ƒê·∫ßu v√†o</h2>
              
              <div className="space-y-4 mb-4">
                {needsMic && (
                  <button
                    onClick={isListening ? stopListening : startListening}
                    className={`w-full flex items-center justify-center gap-2 py-3 px-4 rounded-lg font-semibold transition duration-200 ${
                      isListening
                        ? 'bg-red-500 hover:bg-red-600 text-white'
                        : 'bg-green-500 hover:bg-green-600 text-white'
                    }`}
                  >
                    <Mic className="w-5 h-5" />
                    {isListening ? 'D·ª´ng ghi √¢m' : 'B·∫Øt ƒë·∫ßu ghi √¢m'}
                  </button>
                )}

                {needsCamera && (
                  <button
                    onClick={isCameraOn ? stopCamera : startCamera}
                    className={`w-full flex items-center justify-center gap-2 py-3 px-4 rounded-lg font-semibold transition duration-200 ${
                      isCameraOn
                        ? 'bg-red-500 hover:bg-red-600 text-white'
                        : 'bg-blue-500 hover:bg-blue-600 text-white'
                    }`}
                  >
                    <Camera className="w-5 h-5" />
                    {isCameraOn ? 'T·∫Øt camera' : 'B·∫≠t camera'}
                  </button>
                )}
              </div>

              {needsCamera && isCameraOn && (
                <div className="mb-4">
                  <div className="relative">
                    <video
                      ref={videoRef}
                      autoPlay
                      playsInline
                      className="w-full rounded-lg bg-black"
                      style={{ display: 'block' }}
                    />
                    <canvas
                      ref={canvasRef}
                      className="absolute top-0 left-0 w-full h-full rounded-lg"
                      style={{ pointerEvents: 'none' }}
                    />
                  </div>
                  <p className="text-sm text-gray-500 mt-2 text-center">
                    {isDetecting ? 'üé• ƒêang nh·∫≠n di·ªán c·ª≠ ch·ªâ tay...' : 'Camera ƒëang ho·∫°t ƒë·ªông - S·ª≠ d·ª•ng ng√¥n ng·ªØ k√Ω hi·ªáu'}
                  </p>
                  {detectedText && (
                    <div className="mt-3 p-3 bg-green-50 rounded-lg border-2 border-green-200">
                      <p className="text-sm text-gray-600 mb-1">üìù VƒÉn b·∫£n ƒë√£ nh·∫≠n di·ªán:</p>
                      <p className="text-lg font-semibold text-green-900">{detectedText}</p>
                      <button
                        onClick={() => {
                          setInputText(detectedText);
                          setDetectedText('');
                        }}
                        className="mt-2 px-4 py-2 bg-green-600 hover:bg-green-700 text-white rounded-lg text-sm font-medium transition duration-200"
                      >
                        S·ª≠ d·ª•ng vƒÉn b·∫£n n√†y
                      </button>
                      <button
                        onClick={() => setDetectedText('')}
                        className="mt-2 ml-2 px-4 py-2 bg-gray-300 hover:bg-gray-400 text-gray-700 rounded-lg text-sm font-medium transition duration-200"
                      >
                        X√≥a
                      </button>
                    </div>
                  )}
                </div>
              )}

              {!needsCamera && (
                <div className="mb-4">
                  <label className="block text-sm font-medium text-gray-700 mb-2">
                    Nh·∫≠p vƒÉn b·∫£n:
                  </label>
                  <textarea
                    value={inputText}
                    onChange={(e) => setInputText(e.target.value)}
                    className="w-full p-3 border border-gray-300 rounded-lg h-32 focus:ring-2 focus:ring-indigo-500 focus:border-transparent"
                    placeholder="Nh·∫≠p n·ªôi dung c·∫ßn chuy·ªÉn ƒë·ªïi..."
                  />
                </div>
              )}

              <button
                onClick={processConversion}
                disabled={isProcessing}
                className={`w-full py-3 px-4 rounded-lg font-semibold transition duration-200 ${
                  isProcessing
                    ? 'bg-gray-400 cursor-not-allowed'
                    : 'bg-indigo-600 hover:bg-indigo-700'
                } text-white`}
              >
                {isProcessing ? 'ƒêang x·ª≠ l√Ω...' : 'Chuy·ªÉn ƒë·ªïi'}
              </button>
            </div>

            <div className="bg-white rounded-2xl shadow-xl p-6">
              <h2 className="text-xl font-semibold mb-4 text-gray-900">ƒê·∫ßu ra</h2>
              
              <div className="bg-gray-50 rounded-lg p-4 min-h-[300px]">
                {outputText ? (
                  <div className="space-y-2">
                    <p className="text-gray-800 whitespace-pre-wrap">{outputText}</p>
                  </div>
                ) : (
                  <p className="text-gray-400 text-center mt-12">
                    K·∫øt qu·∫£ chuy·ªÉn ƒë·ªïi s·∫Ω hi·ªÉn th·ªã ·ªü ƒë√¢y
                  </p>
                )}
              </div>

              {outputText && (
                <div className="mt-4 p-3 bg-green-50 rounded-lg">
                  <p className="text-sm text-green-800">‚úì Chuy·ªÉn ƒë·ªïi th√†nh c√¥ng!</p>
                </div>
              )}
            </div>
          </div>
        </div>
      </div>
    );
  }

  return null;
};

export default AccessibilityBridge;